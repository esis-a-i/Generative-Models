{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esis-a-i/Generative-Models/blob/main/HWs/hw1/hw_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUgNFOSlFEzm"
      },
      "source": [
        "# МОиВС \"Генеративные модели\", 5-й модуль\n",
        "\n",
        "# Homework 1\n",
        "\n",
        "В этой домашней работе вам предстоит добавить к BERT'у декодерную часть и решить задачу генерации суммаризаций для текстов новостей на русском языке.\n",
        "\n",
        "Дополнительно к этому на отличную оценку потребуется реализовать подсчет метрик качества и менее жадную стратегию выбора следующего токена для генерации.\n",
        "\n",
        "*Мы сразу вас предостерегаем попасть в петлю бесконечного дообучения модели. Эта домашка не на пробитие скора. Мы будем проверять, что вы, в целом, сделали все верно и смогли получить какую-то более-менее адекватную (такую, которая заметно лучше той, что была до начала обучения) генерацию. Таким образом, если вы видите, что модель учится, не надо дообучать её сутками. Нескольких часов точно должно хватить.*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "По любым вопросам касательно этой домашней работы обращайтесь ко своим ассистентам\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-oW4ttVEL_9",
        "ExecuteTime": {
          "end_time": "2024-10-06T13:33:12.943910Z",
          "start_time": "2024-10-06T13:33:10.715638Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18242098-5d5d-4fc5-988b-06e2c7057591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 471.6/471.6 kB 17.4 MB/s eta 0:00:00\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.0/84.0 kB 7.0 MB/s eta 0:00:00\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 3.7 MB/s eta 0:00:00\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 3.7 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 7.5 MB/s eta 0:00:00\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer\n",
        "from torch import optim\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ygnbZcjlgJR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных (0.5 балла)\n",
        "\n",
        "Мы воспользуемся датасетом с 🤗 Ильи Гусева \"gazeta\". Он представляет собой пары (полный текст новости -- его саммари). Пары были взяты с одноименного сайта в домене .ru\n",
        "\n",
        "Более подробно про датасет можно прочитать [здесь](https://huggingface.co/datasets/IlyaGusev/gazeta)\n",
        "\n"
      ],
      "metadata": {
        "id": "MYW38mH0gKX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDV4tJzzB5Hi"
      },
      "outputs": [],
      "source": [
        "# Загрузим данные с попощью библиотеки библиотеки datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\", split='train[:5%]')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вы должны помнить, что тексты перед подачей в модель необходимо **токенизировать**.\n",
        "\n",
        "Добавьте паддинг до `max_length=512` для обучающих данных, а также до `max_length=128` для меток.\n",
        "\n",
        "Используйте обрезку текстов, длина которых в токенах превышает `max_length`"
      ],
      "metadata": {
        "id": "xOjri9a4h6K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим данные для модели Bert\n",
        "\n",
        "model_name = 'deepvk/bert-base-uncased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess(examples, use_padding=True):\n",
        "  inputs = examples['text']\n",
        "  targets = examples['summary']\n",
        "  if use_padding:\n",
        "    model_inputs = tokenizer(\n",
        "          inputs,\n",
        "          padding='max_length',\n",
        "          max_length=512,\n",
        "          truncation=True,\n",
        "      )\n",
        "    labels = tokenizer(\n",
        "            targets,\n",
        "            padding='max_length',\n",
        "            max_length=128,\n",
        "            truncation=True\n",
        "        )\n",
        "  else:\n",
        "    model_inputs = tokenizer(\n",
        "          inputs,\n",
        "          padding=False,\n",
        "          max_length=512,\n",
        "          truncation=True,\n",
        "      )\n",
        "    labels = tokenizer(\n",
        "            targets,\n",
        "            padding=False,\n",
        "            max_length=128,\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "\n",
        "  return model_inputs"
      ],
      "metadata": {
        "id": "yp19tTXfgHsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess, batched=False)\n",
        "tokenized_dataset.set_format('torch')"
      ],
      "metadata": {
        "id": "qV2U7gzdO-zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Размер батча советуем подбирать таким образом, чтоб утилизировать максимум доступной VRAM"
      ],
      "metadata": {
        "id": "uXQ8gq1UijNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_size = int(0.7 * len(tokenized_dataset))\n",
        "val_size = len(tokenized_dataset) - train_size\n",
        "\n",
        "train_dataset, eval_dataset = torch.utils.data.random_split(tokenized_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "xmMCjFAqSDWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация Decoder-cети (3 балла)\n",
        "\n",
        "В данном разделе вам необходимо **реализовать собственный декодер для генерации текста**.\n",
        "\n",
        "Можете вдохновляться кодом с семинара 1 по GPT. В инициализации весов стоит (но необязательно) проявить смекалку"
      ],
      "metadata": {
        "id": "Z0J1iEfFHxRz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5qSblF1EMEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Класс модели для суммаризации на основе BERT с кастомным декодером\n",
        "\n",
        "class BertSummarizer(nn.Module):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=768, num_decoder_layers=3, num_heads=8, dropout=0.1):\n",
        "        super(BertSummarizer, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Эмбеддинги для токенов на входе в декодер\n",
        "        self.embedding = nn.Embedding(self.bert.config.vocab_size, hidden_size)\n",
        "        if hidden_size == 768:\n",
        "            self.embedding.weight = nn.Parameter(self.bert.embeddings.word_embeddings.weight.clone())\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout, batch_first=True)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_size, self.bert.config.vocab_size)\n",
        "\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "\n",
        "    # Функция для создания маски для предотвращения заглядывания вперед в декодере\n",
        "    def generate_square_subsequent_mask(self, T):\n",
        "        return  torch.triu(torch.ones(T, T), diagonal=1).bool()\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_input_ids):\n",
        "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        memory = encoder_outputs.last_hidden_state  # Выходы BERT для использования в декодере\n",
        "\n",
        "        # Эмбеддинги для входных токенов декодера\n",
        "        embedded = self.embedding(decoder_input_ids)\n",
        "\n",
        "        # Генерация маски для предотвращения заглядывания вперед\n",
        "        decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(1)).to(input_ids.device)\n",
        "        decoder_output = self.decoder(tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask)\n",
        "\n",
        "        output = self.fc_out(decoder_output)\n",
        "        output = output\n",
        "        return self.softmax(output)\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer, max_len=50):\n",
        "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        memory = encoder_outputs.last_hidden_state\n",
        "        batch_size = input_ids.size(0)\n",
        "        # Начинаем с токена [CLS] или [BOS] (начало последовательности)\n",
        "\n",
        "        decoder_input_ids = torch.full((batch_size, 1), tokenizer.cls_token_id, dtype=torch.long).to(input_ids.device)\n",
        "        memory = memory\n",
        "        generated_tokens = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            embedded = self.embedding(decoder_input_ids)\n",
        "\n",
        "            # Генерация маски для предотвращения заглядывания вперед\n",
        "            decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(1)).to(input_ids.device)\n",
        "            decoder_output = self.decoder(tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask)\n",
        "            output = self.fc_out(decoder_output.transpose(0, 1))\n",
        "\n",
        "            # Получаем индекс токена с наибольшей вероятностью.\n",
        "            # Помните, если EOS предсказан, прекращаем генерацию\n",
        "\n",
        "            next_token_id = output.argmax(dim=-1)[-1, :]\n",
        "            if next_token_id == tokenizer.eos_token_id:\n",
        "                break\n",
        "            decoder_input_ids = torch.cat([decoder_input_ids, next_token_id.unsqueeze(0)], dim=-1)\n",
        "\n",
        "        generated_sequence = tokenizer.decode(decoder_input_ids.squeeze().tolist(), skip_special_tokens=True)\n",
        "\n",
        "        return generated_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5VXXCKgecHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986d4ee1-4f6b-43f4-c274-cb8c2457d62c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertSummarizer(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(36000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (embedding): Embedding(36000, 768)\n",
              "  (decoder): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=768, out_features=36000, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Инициализируем нашу модель и посморим на ее архитектруру\n",
        "\n",
        "model = BertSummarizer(bert_model_name=model_name)\n",
        "model = model.to('cuda')\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtvZWsojOh6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "92653609-8a50-46ce-ef01-91fd62df7bf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'##ведо 4х злость философия стих быстрыи детка ##ехав ##рота ##ович ошибо ##мара ##чника 👉🏻 ##хуя стипен ##чатка финала консультацию звуки обошел космоса блокно выборы издалека ще ##лет нуле пузы упор ##нимал цени графи ##78 западе принадлежат гибели круглые брюки покинуть ##илось ##разил волок хол бре mult юбилеи украине храбро roy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Посмотрим на генерацию без обучения\n",
        "\n",
        "eval_data_sample = next(iter(eval_dataloader))\n",
        "model.generate(eval_data_sample['input_ids'][:1].to('cuda'), eval_data_sample['attention_mask'][:1].to('cuda'), tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение модели (1 балл)\n",
        "\n",
        "<small> 0.25 балла за простейший рабочий цикл; </small>\n",
        "\n",
        "<small> +0.5 балла за графики для лосса и метрик на трейне и валидации.</small>\n",
        "\n",
        "В данном разделе вам необходимо **реализовать цикл для обучения модели**\n"
      ],
      "metadata": {
        "id": "1H2L-0BmZyu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример обучения на одной итерации\n",
        "\n",
        "def train_step(model, input_ids, attention_mask, decoder_input_ids, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_ids, attention_mask, decoder_input_ids)\n",
        "    shifted_labels = torch.cat([decoder_input_ids[:, 1:].to('cpu'), torch.full((decoder_input_ids.size(0), 1), tokenizer.pad_token_id)], dim=1).to('cuda')\n",
        "    loss = criterion(outputs.view(-1, outputs.size(-1)), shifted_labels.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "us3xiacHBm-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_step(model, input_ids, attention_mask, decoder_input_ids, criterion):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask, decoder_input_ids)\n",
        "\n",
        "    loss = criterion(outputs.view(-1, outputs.size(-1)), decoder_input_ids.view(-1))\n",
        "  return loss.item()\n",
        "\n",
        "\n",
        "def train_loop(model, train_dataloader, eval_dataloader, epochs=3, learning_rate=1e-4):\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "  train_losses = []\n",
        "  eval_losses = []\n",
        "  for epoch in range(epochs):\n",
        "      print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "      model.train()\n",
        "      epoch_train_loss = 0\n",
        "      for i, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "          if epoch==1:\n",
        "            for param in model.parameters():\n",
        "                if param.requires_grad==True:\n",
        "                    param.lr = learning_rate*(i/len(train_dataloader))\n",
        "\n",
        "          input_ids = batch['input_ids'].to('cuda')\n",
        "          attention_mask = batch['attention_mask'].to('cuda')\n",
        "          decoder_input_ids = batch['labels'].to('cuda')\n",
        "\n",
        "          loss = train_step(model, input_ids, attention_mask, decoder_input_ids, optimizer, criterion)\n",
        "          epoch_train_loss += loss\n",
        "\n",
        "      train_losses.append(epoch_train_loss / len(train_dataloader))\n",
        "      print(f\"Train Loss: {train_losses[-1]}\")\n",
        "\n",
        "      model.eval()\n",
        "      epoch_eval_loss = 0\n",
        "      for batch in tqdm(eval_dataloader):\n",
        "          input_ids = batch['input_ids'].to('cuda')\n",
        "          attention_mask = batch['attention_mask'].to('cuda')\n",
        "          decoder_input_ids = batch['labels'].to('cuda')\n",
        "\n",
        "          loss = evaluate_step(model, input_ids, attention_mask, decoder_input_ids, criterion)\n",
        "          epoch_eval_loss += loss\n",
        "\n",
        "      eval_losses.append(epoch_eval_loss / len(eval_dataloader))\n",
        "      print(f\"Eval Loss: {eval_losses[-1]}\")\n",
        "\n",
        "  return train_losses, eval_losses"
      ],
      "metadata": {
        "id": "tlm2mpBrPa7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, eval_losses = train_loop(model, train_dataloader, eval_dataloader, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uZXT7brezj0",
        "outputId": "807bd162-1264-4df3-8a02-0dd03c8174bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [04:00<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.727054873655798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:30<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 4.438230085372925\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [04:03<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.022258179911067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:29<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 4.562969232642132\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 267/267 [04:02<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.6230416338095504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 115/115 [00:29<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Loss: 4.669821784807288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data_sample = next(iter(eval_dataloader))\n",
        "model.generate(eval_data_sample['input_ids'][:1].to('cuda'), eval_data_sample['attention_mask'][:1].to('cuda'), tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Fays5NI8Ng7u",
        "outputId": "6501fa18-deab-418b-cf1d-99c095ef5848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'« манчестер юнаитед » в первом матче « реал » в первом матче против « реал » в первом матче против « реал » в первом матче против « реал » и « реал » и « реал » и « реал » и « реал » и « реал'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метрики качества (1 балл)\n",
        "\n",
        "<small>По 0.33 балла за реализацию каждой из предлагаемых метрик</small>\n",
        "\n",
        "**Реализуйте функицию для подсчета метрик качества суммаризации.**\n",
        "\n",
        "Докуметация по некотрым метрикам:\n",
        " 1. [HuggingFace Rouge](https://huggingface.co/spaces/evaluate-metric/rouge)\n",
        " 2. [HuggingFace Bleu](https://huggingface.co/spaces/evaluate-metric/bleu)\n",
        " 3. [HuggingFace BERT Score](https://huggingface.co/spaces/evaluate-metric/bertscore)"
      ],
      "metadata": {
        "id": "Fo01OhsoaacU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score\n",
        "!pip install bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YinQP0BYfPoF",
        "outputId": "76949f76-b0a9-416c-dd5f-8fd6df70e2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.4.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.44.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "k33xPxe5Rwkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(predictions, references):\n",
        "    rouge = evaluate.load('rouge')\n",
        "    bleu = evaluate.load('bleu')\n",
        "    bertscore = evaluate.load('bertscore')\n",
        "\n",
        "    rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "    bleu_result = bleu.compute(predictions=predictions, references=references)\n",
        "    bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"ru\")\n",
        "\n",
        "    metrics = {\n",
        "        \"rouge1\": rouge_result['rouge1'],\n",
        "        \"rouge2\": rouge_result['rouge2'],\n",
        "        \"rougeL\": rouge_result['rougeL'],\n",
        "        \"bleu\": bleu_result['bleu'],\n",
        "        \"bert_score_f1\": sum(bertscore_result['f1']) / len(bertscore_result['f1']),\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "mnAQ11F3RxPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, eval_dataloader, tokenizer, max_len=50):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to('cuda')\n",
        "            attention_mask = batch['attention_mask'].to('cuda')\n",
        "            labels = batch['labels']\n",
        "\n",
        "            batch_predictions = []\n",
        "            for i in range(input_ids.size(0)):\n",
        "                output = model.generate(input_ids[i].unsqueeze(0), attention_mask[i].unsqueeze(0), tokenizer, max_len)\n",
        "                batch_predictions.append(output)\n",
        "\n",
        "            predictions.extend(batch_predictions)\n",
        "\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "            references.extend(decoded_labels)\n",
        "\n",
        "    assert len(predictions) == len(references), \"Количество предсказаний не совпадает с количеством ссылок\"\n",
        "\n",
        "    metrics = compute_metrics(predictions, references)\n",
        "    print(\"Evaluation Metrics:\", metrics)\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "BBNcGXt8aSJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(model, eval_dataloader, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "862cca6d59b24b729c9b374b54eee803",
            "8117320d04ff4892beef720aa286ed64",
            "2d947484cac54218ac0ee8d044fda8d8",
            "42557af613cf4342a16fa770e343dbab",
            "0884c9e8678d4430b325f76f7d42bfa4",
            "3fac64324ea748eb95843684f7a2afe4",
            "add7b2219d1f4202b94bc75e6271702d",
            "c6afb35a2ce14d31bb95303084a70e8e",
            "10ee1f802a2647b9a82e9608f264449f",
            "b153906977f24b659e9c10ccafcce6c7",
            "6d7ec675bce74738aafda8265ff8dfe4",
            "ecff5cdb02fb4bbb84e0d72da6207076",
            "70935619775d43689d5373b2f49fd20f",
            "c8d2027f4b374f5cb0b840d2dc9a011e",
            "3e0e4c8a5ea049eab751e14036e4414d",
            "a7d1fae46dc948f895745a7fc8ea6508",
            "c5fd1218dc7b4de7b832c5c4f0448170",
            "b92af074789847f3998c6070cef28c93",
            "b81e82c649614983ab394fc78390295c",
            "13ccbdd4058c45bba5b5335c70e347a4",
            "de62d50048c647afb48af3bd01eff46a",
            "e13f50ea6b0a497f89e63491aaf2f915",
            "d5c561adbbc443729969ac1194c78f62",
            "e4da1b542e2443499b5f307c3fe15d15",
            "2fec5e5e47e44397b1ca4fe5a25839a8",
            "f1f82e6f79ee4bdc9a39d2b7c5df6002",
            "f9215f66d4d24617b3f80232ec607ec3",
            "d41111dd337c483d8d9f223f988d5941",
            "aa8e01804c0643eebbcf418a610c27ff",
            "0e7768018e9c4aa4be0203ed32f5c9f4",
            "ba61f3fae9c9404b9c4911ce589afcd6",
            "00d949c6cf4741f180ffd34d7ed6e111",
            "7254425d053f455c93d864633db4df9b",
            "559df4c88fd44d54b13e8af2c7ef0f20",
            "5fd1ce1f7a134c84a5545c0806222623",
            "92da56e299814078aef8c528c9130921",
            "fcb383ff73474ea7bd2fae666a288359",
            "9efa4d9555324b22b5282396473a8555",
            "dd2f11ee53aa4a6382c43462ba5be30b",
            "c73513e375e0471f8d5d637ccc2d6c3a",
            "a4943751cb2e4228967d95046e64d7a0",
            "cb6a4f82d4294e57b762c2fc4ed556b9",
            "c7022cbe4fbc44119bdef5ee07f26ef7",
            "6bc2c5c20a704930a47e0d1c018b747c",
            "2c8b800aa54d486ca87c08cf1fdeee73",
            "dd80dd3f04294573977edcec6cc8e8b7",
            "bf460866af5e47feb05d0b279279324b",
            "d47dbf3113a04923bf254b29d95ce056",
            "2e2269cd8f8c4018a6ad1a6e2ec6780b",
            "09ee10463e6140c0bcb0427085898993",
            "35ebc2bad96345d69f5fe758c583049b",
            "37ffee5013634c918f381a32f5f3bb7d",
            "3e7c244d405b4354a6308fce41c1e813",
            "ccd3800432fd405e860f674020b4cc16",
            "413688a74c954b2f891cb9b8e6b2310c"
          ]
        },
        "id": "PW-7PmOiTeru",
        "outputId": "154bdd6c-4af4-4fe4-8f0d-56518a13f4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 115/115 [04:02<00:00,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "862cca6d59b24b729c9b374b54eee803"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecff5cdb02fb4bbb84e0d72da6207076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5c561adbbc443729969ac1194c78f62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "559df4c88fd44d54b13e8af2c7ef0f20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c8b800aa54d486ca87c08cf1fdeee73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics: {'rouge1': 0.0014775135373852409, 'rouge2': 0.0, 'rougeL': 0.001491086327151901, 'bleu': 0.0, 'bert_score_f1': 0.6300963460421953}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 0.0014775135373852409,\n",
              " 'rouge2': 0.0,\n",
              " 'rougeL': 0.001491086327151901,\n",
              " 'bleu': 0.0,\n",
              " 'bert_score_f1': 0.6300963460421953}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение модели (0.5 балла)\n",
        "**Обучите модель, сохраните лучшую версию** (метод `.save_pretrained()` объекта класса AutoModel... или `torch.save()`) **и добавьте пример генерации**. Учтите, что если изменялся токенизатор (а лучше просто по умолчанию), его тоже нужно сохранить. Если планируете продолжить обучение\n",
        "\n",
        "Для сравнения оценки качества генерации по значениям реализованных метрик можете запустить ruT5-small без дообучения. Мы намеренно даем бейзлайн именно в таком виде."
      ],
      "metadata": {
        "id": "BQ5GaAZ1chBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "7CIP5PfVVE1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"YOUR MODEL\")\n",
        "summary = #<YOUR CODE HERE>"
      ],
      "metadata": {
        "id": "KHu9RzbQcceV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация менее жадных стратегий выбора следующего токена (4 балла)\n",
        "Всегда ли выбор наиболее вероятного токена на каждом шаге – это лучшая стратегия для генерации текста?\n",
        "\n",
        "<details>\n",
        "    <summary>Спойлер</summary>\n",
        "    <p>Нет</p>\n",
        "</details>\n",
        "\n",
        "**Сравнение стратегий для генерации текста:**\n",
        "\n",
        "| Strategy | Description | Pros & Cons |\n",
        "| --- | --- | --- |\n",
        "| Greedy Search | Chooses the word with the highest probability as the next word in the sequence. | **Pros:** Simple and fast. <br><br/> **Cons:** Can lead to repetitive and incoherent text. |\n",
        "| Sampling with Temperature | Introduces randomness in the word selection. A higher temperature leads to more randomness. | **Pros:** Allows exploration and diverse output. <br><br/> **Cons:** Higher temperatures can lead to nonsensical outputs. |\n",
        "| Nucleus Sampling (Top-p Sampling) | Selects the next word from a truncated vocabulary, the \"nucleus\" of words <br/> that have a cumulative probability exceeding a pre-specified threshold (p). | **Pros:** Balances diversity and quality. <br><br/> **Cons:** Setting an optimal 'p' can be tricky. |\n",
        "| Beam Search | Explores multiple hypotheses (sequences of words) at each step, and keeps <br/> the 'k' most likely, where 'k' is the beam width. | **Pros:** Produces more reliable results than greedy search. <br><br/> **Cons:** Can lack diversity and lead to generic responses. |\n",
        "| Top-k Sampling | Randomly selects the next word from the top 'k' words with the highest probabilities. | **Pros:** Introduces randomness, increasing output diversity. <br><br/> **Cons:** Random selection can sometimes lead to less coherent outputs. |\n",
        "| Length Normalization | Prevents the model from favoring shorter sequences by dividing the log probabilities <br/> by the sequence length raised to some power. | **Pros:** Makes longer and potentially more informative sequences more likely. <br><br/> **Cons:** Tuning the normalization factor can be difficult. |\n",
        "| Stochastic Beam Search | Introduces randomness into the selection process of the 'k' hypotheses in beam search. | **Pros:** Increases diversity in the generated text. <br><br/> **Cons:** The trade-off between diversity and quality can be tricky to manage. |\n",
        "| Decoding with Minimum Bayes Risk (MBR) | Chooses the hypothesis (out of many) that minimizes expected loss under a loss function. | **Pros:** Optimizes the output according to a specific loss function. <br><br/> **Cons:** Computationally more complex and requires a good loss function. |\n",
        "\n",
        "Ссылки на докуметацию:\n",
        "- [reference for `AutoModelForCausalLM.generate()`](https://huggingface.co/docs/transformers/v4.29.1/en/main_classes/text_generation#transformers.GenerationMixin.generate)\n",
        "- [reference for `AutoTokenizer.decode()`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.decode)\n",
        "- Huggingface [docs on generation strategies](https://huggingface.co/docs/transformers/generation_strategies)"
      ],
      "metadata": {
        "id": "vbQH_vj6d2Ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Дополните метод `generate` в модели, чтобы получать топ-k самых вероятных токена и их \"вероятности\"** (1 балл).   \n",
        "\n",
        "**2. Реализуйте стратегию Nucleus Sampling в методе `generate`** (1 балл)\n",
        "\n",
        "**3. Реализуйте стратегию Beam Search** (2 балла)\n",
        "\n",
        "Получилось ли улучшить генерацию?"
      ],
      "metadata": {
        "id": "uQF4Vc3msKpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def top_k_sampling(logits, k):\n",
        "    top_k_logits, top_k_indices = torch.topk(logits, k)\n",
        "    top_k_probs = F.softmax(top_k_logits, dim=-1)\n",
        "    next_token = torch.multinomial(top_k_probs, num_samples=1)\n",
        "    return top_k_indices[next_token]"
      ],
      "metadata": {
        "id": "JRfAEfP5kHcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nucleus_sampling(logits, p):\n",
        "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "    sorted_indices_to_remove = cumulative_probs > p\n",
        "\n",
        "    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "    sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "    sorted_logits[sorted_indices_to_remove] = -float('Inf')\n",
        "\n",
        "    next_token = torch.multinomial(F.softmax(sorted_logits, dim=-1), num_samples=1)\n",
        "    return sorted_indices[next_token]"
      ],
      "metadata": {
        "id": "BETJTwfGOBlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Класс модели для суммаризации на основе BERT с кастомным декодером и выбором стратегии\n",
        "\n",
        "class BertSummarizerCustomStrategy(nn.Module):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=768, num_decoder_layers=3, num_heads=8, dropout=0.1):\n",
        "        super(BertSummarizerCustomStrategy, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Эмбеддинги для токенов на входе в декодер\n",
        "        self.embedding = nn.Embedding(self.bert.config.vocab_size, hidden_size)\n",
        "\n",
        "        #<YOUR CODE HERE>\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_size, self.bert.config.vocab_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    # Функция для создания маски для предотвращения заглядывания вперед в декодере\n",
        "    def generate_square_subsequent_mask(self, size):\n",
        "        #<YOUR CODE HERE>\n",
        "        mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_input_ids):\n",
        "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        memory = encoder_outputs.last_hidden_state  # Выходы BERT для использования в декодере\n",
        "\n",
        "        # Эмбеддинги для входных токенов декодера\n",
        "        embedded = self.embedding(decoder_input_ids).transpose(0, 1)\n",
        "        memory = memory.transpose(0, 1)\n",
        "\n",
        "        decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(0)).to(input_ids.device)\n",
        "\n",
        "        decoder_output = self.decoder(tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask)\n",
        "\n",
        "        #<YOUR CODE HERE>\n",
        "        output = self.fc_out(decoder_output.transpose(0, 1))\n",
        "        return output\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer, max_len=50, strategy='top_k', top_k=5, top_p=0.9, num_beams=3):\n",
        "      if strategy == 'beam_search':\n",
        "        return self.beam_search(input_ids, attention_mask, tokenizer, max_len, num_beams)\n",
        "\n",
        "      encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      memory = encoder_outputs.last_hidden_state.transpose(0, 1)\n",
        "      batch_size = input_ids.size(0)\n",
        "\n",
        "      decoder_input_ids = torch.full((batch_size, 1), tokenizer.cls_token_id, dtype=torch.long).to(input_ids.device)\n",
        "\n",
        "      for _ in range(max_len):\n",
        "          embedded = self.embedding(decoder_input_ids).transpose(0, 1)\n",
        "          decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(0)).to(input_ids.device)\n",
        "          decoder_output = self.decoder(tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask)\n",
        "          output = self.fc_out(decoder_output.transpose(0, 1))\n",
        "          next_token_logits = output[:, -1, :]\n",
        "\n",
        "          if strategy == 'top_k':\n",
        "              next_token = top_k_sampling(next_token_logits, top_k)\n",
        "          elif strategy == 'nucleus':\n",
        "              next_token = nucleus_sampling(next_token_logits, top_p)\n",
        "          else:\n",
        "              next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(-1)\n",
        "\n",
        "          decoder_input_ids = torch.cat((decoder_input_ids, next_token), dim=1)\n",
        "\n",
        "          if next_token.item() == tokenizer.eos_token_id:\n",
        "              break\n",
        "\n",
        "      return tokenizer.decode(decoder_input_ids.squeeze().tolist(), skip_special_tokens=True)\n",
        "\n",
        "    def beam_search(self, input_ids, attention_mask, tokenizer, max_len=50, num_beams=3):\n",
        "      encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      memory = encoder_outputs.last_hidden_state.transpose(0, 1)\n",
        "      batch_size = input_ids.size(0)\n",
        "\n",
        "      decoder_input_ids = torch.full((batch_size * num_beams, 1), tokenizer.cls_token_id, dtype=torch.long).to(input_ids.device)\n",
        "      beam_scores = torch.zeros((batch_size * num_beams, 1), dtype=torch.float, device=input_ids.device)\n",
        "\n",
        "      for _ in range(max_len):\n",
        "          embedded = self.embedding(decoder_input_ids).transpose(0, 1)\n",
        "          decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(0)).to(input_ids.device)\n",
        "          decoder_output = self.decoder(tgt=embedded, memory=memory.repeat(1, num_beams, 1), tgt_mask=decoder_attention_mask)\n",
        "          output = self.fc_out(decoder_output.transpose(0, 1))\n",
        "          next_token_logits = output[:, -1, :]\n",
        "\n",
        "          next_token_scores = F.log_softmax(next_token_logits, dim=-1)\n",
        "          scores = beam_scores + next_token_scores\n",
        "          scores = scores.view(batch_size, num_beams * self.bert.config.vocab_size)\n",
        "\n",
        "          next_beam_scores, next_beam_tokens = torch.topk(scores, num_beams, dim=1)\n",
        "          beam_indices = next_beam_tokens // self.bert.config.vocab_size\n",
        "          decoder_input_ids = torch.cat((decoder_input_ids[beam_indices], next_beam_tokens % self.bert.config.vocab_size), dim=2)\n",
        "\n",
        "      generated_sequences = []\n",
        "      for i in range(batch_size):\n",
        "          sequence = decoder_input_ids[i * num_beams + beam_indices[i][0], :]\n",
        "          generated_sequences.append(tokenizer.decode(sequence.tolist(), skip_special_tokens=True))\n",
        "      return generated_sequences\n"
      ],
      "metadata": {
        "id": "eiSv4M9HOfs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86da729e-ff78-48f6-a3ca-627998b5da9a",
        "id": "bJCJa8KmPGst"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertSummarizerCustomStrategy(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(36000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (embedding): Embedding(36000, 768)\n",
              "  (decoder): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=768, out_features=36000, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Инициализируем нашу модель и посморим на ее архитектруру\n",
        "\n",
        "model = BertSummarizerCustomStrategy(bert_model_name=model_name)\n",
        "model = model.to('cuda')\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Послевкусие (0 баллов)\n",
        "\n",
        "Если эта домашняя работа показалась вам недостаточно большой, предлагаем провести следующий эксперимент:\n",
        "\n",
        "- от имеющейся модели \"откусить\" только декодерную часть (откусить также можно от ruT5-small);\n",
        "- немного дообучить (что называется, по вкусу);\n",
        "- посмотреть качество генерации по метрикам и \"глазами\";\n",
        "- сравнить полученное с Encoder-Decoder архитектурой;\n",
        "- ответить на вопрос \"Дает ли применение Encoder-Decoder архитектуры значительный буст в качестве генерации, или это некоторый overkill?\" (базово, ответ лежит на поверхности 😸)\n",
        "\n",
        "Ещё более опционально можно:\n",
        "- почитать про возможности генерации Encoder-only архитектурными решениями (BERT, e.g.)\n",
        "- сравнить с генерацией только Decoder'ом и both Encoder-Decoder'ом;\n",
        "- в т.ч. подобрать число обучаемых параметров таким образом, чтоб оно было примерно одинаковым для каждого инстанса моделей (их, инстансов, будет 3 -- только энкодер, только декодер и энкодер-декодер).\n",
        "\n",
        "*Вообще ориентироваться следует на следующее утверждение: \"Только энкодерные архитектуры (BERT, e.g.) хороши для понимания текста (получения эмеддингов), лишь декодерные (GPT, например) -- для генерации, энкодер-декодерные (скажем, T5) -- для обеих задач\"*"
      ],
      "metadata": {
        "id": "QbiksVMOOvO8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZM1xLliO1QM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "862cca6d59b24b729c9b374b54eee803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8117320d04ff4892beef720aa286ed64",
              "IPY_MODEL_2d947484cac54218ac0ee8d044fda8d8",
              "IPY_MODEL_42557af613cf4342a16fa770e343dbab"
            ],
            "layout": "IPY_MODEL_0884c9e8678d4430b325f76f7d42bfa4"
          }
        },
        "8117320d04ff4892beef720aa286ed64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fac64324ea748eb95843684f7a2afe4",
            "placeholder": "​",
            "style": "IPY_MODEL_add7b2219d1f4202b94bc75e6271702d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2d947484cac54218ac0ee8d044fda8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6afb35a2ce14d31bb95303084a70e8e",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10ee1f802a2647b9a82e9608f264449f",
            "value": 49
          }
        },
        "42557af613cf4342a16fa770e343dbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b153906977f24b659e9c10ccafcce6c7",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7ec675bce74738aafda8265ff8dfe4",
            "value": " 49.0/49.0 [00:00&lt;00:00, 3.35kB/s]"
          }
        },
        "0884c9e8678d4430b325f76f7d42bfa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fac64324ea748eb95843684f7a2afe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add7b2219d1f4202b94bc75e6271702d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6afb35a2ce14d31bb95303084a70e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ee1f802a2647b9a82e9608f264449f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b153906977f24b659e9c10ccafcce6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7ec675bce74738aafda8265ff8dfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecff5cdb02fb4bbb84e0d72da6207076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70935619775d43689d5373b2f49fd20f",
              "IPY_MODEL_c8d2027f4b374f5cb0b840d2dc9a011e",
              "IPY_MODEL_3e0e4c8a5ea049eab751e14036e4414d"
            ],
            "layout": "IPY_MODEL_a7d1fae46dc948f895745a7fc8ea6508"
          }
        },
        "70935619775d43689d5373b2f49fd20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5fd1218dc7b4de7b832c5c4f0448170",
            "placeholder": "​",
            "style": "IPY_MODEL_b92af074789847f3998c6070cef28c93",
            "value": "config.json: 100%"
          }
        },
        "c8d2027f4b374f5cb0b840d2dc9a011e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81e82c649614983ab394fc78390295c",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13ccbdd4058c45bba5b5335c70e347a4",
            "value": 625
          }
        },
        "3e0e4c8a5ea049eab751e14036e4414d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de62d50048c647afb48af3bd01eff46a",
            "placeholder": "​",
            "style": "IPY_MODEL_e13f50ea6b0a497f89e63491aaf2f915",
            "value": " 625/625 [00:00&lt;00:00, 49.3kB/s]"
          }
        },
        "a7d1fae46dc948f895745a7fc8ea6508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5fd1218dc7b4de7b832c5c4f0448170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92af074789847f3998c6070cef28c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b81e82c649614983ab394fc78390295c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ccbdd4058c45bba5b5335c70e347a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de62d50048c647afb48af3bd01eff46a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13f50ea6b0a497f89e63491aaf2f915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5c561adbbc443729969ac1194c78f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4da1b542e2443499b5f307c3fe15d15",
              "IPY_MODEL_2fec5e5e47e44397b1ca4fe5a25839a8",
              "IPY_MODEL_f1f82e6f79ee4bdc9a39d2b7c5df6002"
            ],
            "layout": "IPY_MODEL_f9215f66d4d24617b3f80232ec607ec3"
          }
        },
        "e4da1b542e2443499b5f307c3fe15d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41111dd337c483d8d9f223f988d5941",
            "placeholder": "​",
            "style": "IPY_MODEL_aa8e01804c0643eebbcf418a610c27ff",
            "value": "vocab.txt: 100%"
          }
        },
        "2fec5e5e47e44397b1ca4fe5a25839a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7768018e9c4aa4be0203ed32f5c9f4",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba61f3fae9c9404b9c4911ce589afcd6",
            "value": 995526
          }
        },
        "f1f82e6f79ee4bdc9a39d2b7c5df6002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d949c6cf4741f180ffd34d7ed6e111",
            "placeholder": "​",
            "style": "IPY_MODEL_7254425d053f455c93d864633db4df9b",
            "value": " 996k/996k [00:00&lt;00:00, 3.03MB/s]"
          }
        },
        "f9215f66d4d24617b3f80232ec607ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41111dd337c483d8d9f223f988d5941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8e01804c0643eebbcf418a610c27ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e7768018e9c4aa4be0203ed32f5c9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba61f3fae9c9404b9c4911ce589afcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00d949c6cf4741f180ffd34d7ed6e111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7254425d053f455c93d864633db4df9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "559df4c88fd44d54b13e8af2c7ef0f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fd1ce1f7a134c84a5545c0806222623",
              "IPY_MODEL_92da56e299814078aef8c528c9130921",
              "IPY_MODEL_fcb383ff73474ea7bd2fae666a288359"
            ],
            "layout": "IPY_MODEL_9efa4d9555324b22b5282396473a8555"
          }
        },
        "5fd1ce1f7a134c84a5545c0806222623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2f11ee53aa4a6382c43462ba5be30b",
            "placeholder": "​",
            "style": "IPY_MODEL_c73513e375e0471f8d5d637ccc2d6c3a",
            "value": "tokenizer.json: 100%"
          }
        },
        "92da56e299814078aef8c528c9130921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4943751cb2e4228967d95046e64d7a0",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb6a4f82d4294e57b762c2fc4ed556b9",
            "value": 1961828
          }
        },
        "fcb383ff73474ea7bd2fae666a288359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7022cbe4fbc44119bdef5ee07f26ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_6bc2c5c20a704930a47e0d1c018b747c",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 17.9MB/s]"
          }
        },
        "9efa4d9555324b22b5282396473a8555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2f11ee53aa4a6382c43462ba5be30b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73513e375e0471f8d5d637ccc2d6c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4943751cb2e4228967d95046e64d7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6a4f82d4294e57b762c2fc4ed556b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7022cbe4fbc44119bdef5ee07f26ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc2c5c20a704930a47e0d1c018b747c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c8b800aa54d486ca87c08cf1fdeee73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd80dd3f04294573977edcec6cc8e8b7",
              "IPY_MODEL_bf460866af5e47feb05d0b279279324b",
              "IPY_MODEL_d47dbf3113a04923bf254b29d95ce056"
            ],
            "layout": "IPY_MODEL_2e2269cd8f8c4018a6ad1a6e2ec6780b"
          }
        },
        "dd80dd3f04294573977edcec6cc8e8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09ee10463e6140c0bcb0427085898993",
            "placeholder": "​",
            "style": "IPY_MODEL_35ebc2bad96345d69f5fe758c583049b",
            "value": "model.safetensors: 100%"
          }
        },
        "bf460866af5e47feb05d0b279279324b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37ffee5013634c918f381a32f5f3bb7d",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e7c244d405b4354a6308fce41c1e813",
            "value": 714290682
          }
        },
        "d47dbf3113a04923bf254b29d95ce056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd3800432fd405e860f674020b4cc16",
            "placeholder": "​",
            "style": "IPY_MODEL_413688a74c954b2f891cb9b8e6b2310c",
            "value": " 714M/714M [00:06&lt;00:00, 239MB/s]"
          }
        },
        "2e2269cd8f8c4018a6ad1a6e2ec6780b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ee10463e6140c0bcb0427085898993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ebc2bad96345d69f5fe758c583049b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ffee5013634c918f381a32f5f3bb7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e7c244d405b4354a6308fce41c1e813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccd3800432fd405e860f674020b4cc16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413688a74c954b2f891cb9b8e6b2310c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}